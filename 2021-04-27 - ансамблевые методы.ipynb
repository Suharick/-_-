{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "graduate-facial",
   "metadata": {},
   "source": [
    "# Ансамблевые методы повышения качества моделирования"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "young-remedy",
   "metadata": {},
   "source": [
    "Рассмотрим задачу классификации (данные про диабет)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "executive-response",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas import read_csv\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import KFold, cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "general-pharmacy",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>preg</th>\n",
       "      <th>plas</th>\n",
       "      <th>pres</th>\n",
       "      <th>skin</th>\n",
       "      <th>test</th>\n",
       "      <th>mass</th>\n",
       "      <th>pedi</th>\n",
       "      <th>age</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>148</td>\n",
       "      <td>72</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>33.6</td>\n",
       "      <td>0.627</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>85</td>\n",
       "      <td>66</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>26.6</td>\n",
       "      <td>0.351</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8</td>\n",
       "      <td>183</td>\n",
       "      <td>64</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>23.3</td>\n",
       "      <td>0.672</td>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>89</td>\n",
       "      <td>66</td>\n",
       "      <td>23</td>\n",
       "      <td>94</td>\n",
       "      <td>28.1</td>\n",
       "      <td>0.167</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>137</td>\n",
       "      <td>40</td>\n",
       "      <td>35</td>\n",
       "      <td>168</td>\n",
       "      <td>43.1</td>\n",
       "      <td>2.288</td>\n",
       "      <td>33</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>116</td>\n",
       "      <td>74</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>25.6</td>\n",
       "      <td>0.201</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>3</td>\n",
       "      <td>78</td>\n",
       "      <td>50</td>\n",
       "      <td>32</td>\n",
       "      <td>88</td>\n",
       "      <td>31.0</td>\n",
       "      <td>0.248</td>\n",
       "      <td>26</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>10</td>\n",
       "      <td>115</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>35.3</td>\n",
       "      <td>0.134</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2</td>\n",
       "      <td>197</td>\n",
       "      <td>70</td>\n",
       "      <td>45</td>\n",
       "      <td>543</td>\n",
       "      <td>30.5</td>\n",
       "      <td>0.158</td>\n",
       "      <td>53</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>8</td>\n",
       "      <td>125</td>\n",
       "      <td>96</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.232</td>\n",
       "      <td>54</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   preg  plas  pres  skin  test  mass   pedi  age  class\n",
       "0     6   148    72    35     0  33.6  0.627   50      1\n",
       "1     1    85    66    29     0  26.6  0.351   31      0\n",
       "2     8   183    64     0     0  23.3  0.672   32      1\n",
       "3     1    89    66    23    94  28.1  0.167   21      0\n",
       "4     0   137    40    35   168  43.1  2.288   33      1\n",
       "5     5   116    74     0     0  25.6  0.201   30      0\n",
       "6     3    78    50    32    88  31.0  0.248   26      1\n",
       "7    10   115     0     0     0  35.3  0.134   29      0\n",
       "8     2   197    70    45   543  30.5  0.158   53      1\n",
       "9     8   125    96     0     0   0.0  0.232   54      1"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filename = 'git/data/pima-indians-diabetes.data.csv'\n",
    "names = ['preg', 'plas', 'pres', 'skin', 'test', 'mass', 'pedi', 'age', 'class']\n",
    "dataframe = read_csv(filename, names=names)\n",
    "dataframe.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "intense-explosion",
   "metadata": {},
   "outputs": [],
   "source": [
    "array = dataframe.values\n",
    "X = array[:,0:8]\n",
    "Y = array[:,8]\n",
    "\n",
    "seed = 7\n",
    "kFold = KFold(n_splits=10, random_state=seed, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "painted-antarctica",
   "metadata": {},
   "source": [
    "<center>\n",
    "<h1>Bagging</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "muslim-moses",
   "metadata": {},
   "source": [
    "## Bagging Decision Trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "optional-interest",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "historical-receipt",
   "metadata": {},
   "outputs": [],
   "source": [
    "cart = DecisionTreeClassifier()\n",
    "num_trees = 100\n",
    "model_bagging = BaggingClassifier(base_estimator=cart, n_estimators=num_trees, random_state=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "impressive-noise",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7578263841421736\n"
     ]
    }
   ],
   "source": [
    "results_bagging = cross_val_score(model_bagging, X, Y, cv=kFold)\n",
    "print(results_bagging.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cleared-roberts",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "median-router",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "corrected-malpractice",
   "metadata": {},
   "outputs": [],
   "source": [
    "# создается 100 случайных выборок и подбираем 3 случайных признака в каждом ветвлении дерева и по наиболее важному \n",
    "# признаку идет разветвление. всего 100 таких деревьев\n",
    "num_trees = 100\n",
    "max_features = 3\n",
    "model_RandomForest = RandomForestClassifier(n_estimators=num_trees, max_features=max_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "weird-stream",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7629870129870131\n"
     ]
    }
   ],
   "source": [
    "results_RandomForest = cross_val_score(model_RandomForest, X, Y, cv=kFold)\n",
    "print(results_RandomForest.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "executive-uncertainty",
   "metadata": {},
   "source": [
    "получили получше результат"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "quiet-pound",
   "metadata": {},
   "source": [
    "## Extra Trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "weird-psychiatry",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import ExtraTreesClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "champion-fault",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_trees = 100\n",
    "max_features = 7\n",
    "model_ExtraTrees = ExtraTreesClassifier(n_estimators=num_trees, max_features=max_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "random-painting",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7656185919343814\n"
     ]
    }
   ],
   "source": [
    "results_ExtraTrees = cross_val_score(model_ExtraTrees, X, Y, cv=kFold)\n",
    "print(results_ExtraTrees.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "accessory-georgia",
   "metadata": {},
   "source": [
    "<center>\n",
    "<h1>Boosting (улучшение модели)</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "impaired-practitioner",
   "metadata": {},
   "source": [
    "## AdaBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "vulnerable-elevation",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "floral-cream",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_tress = 30\n",
    "model_AdaBoost = AdaBoostClassifier(n_estimators=num_trees, random_state=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "aging-validation",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7578605604921395\n"
     ]
    }
   ],
   "source": [
    "results_AdaBoost = cross_val_score(model_AdaBoost, X, Y, cv=kFold)\n",
    "print(results_AdaBoost.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "personal-andrews",
   "metadata": {},
   "source": [
    "## Gradient Boosting Machines"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "juvenile-category",
   "metadata": {},
   "source": [
    "подвержен переобучению"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "missing-cholesterol",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "hundred-pharmacology",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_tress = 100\n",
    "model_GBM = GradientBoostingClassifier(n_estimators=num_trees, random_state=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "alert-thriller",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7591934381408066\n"
     ]
    }
   ],
   "source": [
    "results_GBM = cross_val_score(model_GBM, X, Y, cv=kFold)\n",
    "print(results_GBM.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "composed-stationery",
   "metadata": {},
   "source": [
    "## XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "sought-title",
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "steady-freight",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_tress = 100\n",
    "model_XGBoost = XGBClassifier(seed=seed, n_estimators=num_trees, max_features=7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "governmental-doctrine",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\program files\\python39\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "c:\\program files\\python39\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "c:\\program files\\python39\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10:10:40] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"max_features\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[10:10:40] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[10:10:40] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"max_features\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[10:10:40] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[10:10:40] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"max_features\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[10:10:40] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\program files\\python39\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "c:\\program files\\python39\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "c:\\program files\\python39\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10:10:40] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"max_features\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[10:10:40] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[10:10:40] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"max_features\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[10:10:40] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[10:10:40] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"max_features\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[10:10:40] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\program files\\python39\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "c:\\program files\\python39\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "c:\\program files\\python39\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10:10:40] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"max_features\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[10:10:40] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[10:10:40] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"max_features\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[10:10:40] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[10:10:41] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"max_features\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[10:10:41] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[10:10:41] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"max_features\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[10:10:41] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "0.7252563226247437\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\program files\\python39\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    }
   ],
   "source": [
    "results_XGBoost = cross_val_score(model_XGBoost, X, Y, cv=kFold)\n",
    "print(results_XGBoost.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "manufactured-elevation",
   "metadata": {},
   "source": [
    "## Voting (голосование)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "italic-louis",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "from sklearn.ensemble import VotingClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dangerous-notion",
   "metadata": {},
   "source": [
    "объединение моделей в один метод "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "growing-coating",
   "metadata": {},
   "outputs": [],
   "source": [
    "estimators = []\n",
    "\n",
    "model1 = LogisticRegression(solver='liblinear')\n",
    "model2 = DecisionTreeClassifier()\n",
    "model3 = SVC(gamma='auto')\n",
    "\n",
    "estimators.append(('Logistic', model1))\n",
    "estimators.append(('DecisionTree', model2))\n",
    "estimators.append(('svm', model3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "electric-artist",
   "metadata": {},
   "source": [
    "на основе списка создадим ансамбль"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "greek-economics",
   "metadata": {},
   "outputs": [],
   "source": [
    "ensemble = VotingClassifier(estimators)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "australian-tract",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7514012303485987\n"
     ]
    }
   ],
   "source": [
    "results_voting = cross_val_score(ensemble, X, Y, cv=kFold)\n",
    "print(results_voting.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "median-shopper",
   "metadata": {},
   "source": [
    "## Grid Search Parameter Tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "funky-lemon",
   "metadata": {},
   "source": [
    "ridge (гребневая регрессия) для классификации. есть параметр альфа, отвечающий за штраф. \n",
    "определим этот параметр альфа"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "stuffed-newton",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.linear_model import RidgeClassifier\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "billion-violation",
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha_list = np.array([1, 0.1, 0.01, 0.001, 0.0001, 0])\n",
    "param_grid = dict(alpha=alpha_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "posted-venice",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_Ridge = RidgeClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "detected-appearance",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid = GridSearchCV(estimator=model_Ridge, param_grid=param_grid, cv=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "stone-terrorist",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=3, estimator=RidgeClassifier(),\n",
       "             param_grid={'alpha': array([1.e+00, 1.e-01, 1.e-02, 1.e-03, 1.e-04, 0.e+00])})"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.fit(X, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "final-comparison",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Наилучший критерий качества = 0.7708333333333334 \n",
      "Соответствующий параметр ALPHA = 1.0\n"
     ]
    }
   ],
   "source": [
    "print('Наилучший критерий качества =', grid.best_score_, '\\nСоответствующий параметр ALPHA =', grid.best_estimator_.alpha)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "higher-banks",
   "metadata": {},
   "source": [
    "## Random Grid Search Parameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "blond-swedish",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from scipy.stats import uniform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "standing-mount",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {'alpha':uniform()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "drawn-sphere",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_Ridge = RidgeClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "mineral-prison",
   "metadata": {},
   "outputs": [],
   "source": [
    "rsearch = RandomizedSearchCV(estimator=model_Ridge, param_distributions=param_grid, n_iter=100, cv=3, random_state=7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "cosmetic-leadership",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=3, estimator=RidgeClassifier(), n_iter=100,\n",
       "                   param_distributions={'alpha': <scipy.stats._distn_infrastructure.rv_frozen object at 0x000001EC2B80F250>},\n",
       "                   random_state=7)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rsearch.fit(X, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "written-print",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Наилучший критерий качества = 0.7708333333333334 \n",
      "Соответствующий параметр ALPHA = 0.07630828937395717\n"
     ]
    }
   ],
   "source": [
    "print('Наилучший критерий качества =', rsearch.best_score_, '\\nСоответствующий параметр ALPHA =', rsearch.best_estimator_.alpha)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "seasonal-strike",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
